{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "# 4_Evaluation_Comparison.ipynb\n",
        "\n",
        "Ce notebook a pour objectif de consolider les résultats de tous les modèles\n",
        "(filtrage collaboratif, SVD, et Deep Learning), de les comparer et de visualiser\n",
        "leurs performances. Enfin, nous montrerons comment utiliser le modèle de Deep Learning\n",
        "pour générer des recommandations personnalisées.\n",
        "\"\"\"\n",
        "\n",
        "# 1. Importation des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from surprise import dump # Pour charger le modèle SVD\n",
        "\n",
        "print(\"Bibliothèques importées avec succès.\")\n",
        "print(f\"Version de TensorFlow : {tf.__version__}\")\n",
        "\n",
        "# 2. Chargement des données et des mappings\n",
        "try:\n",
        "    # Charger les données de test pour les vraies notes\n",
        "    test_df = pd.read_csv('../data/test_ratings.csv')\n",
        "\n",
        "    # Charger les prédictions du modèle Deep Learning\n",
        "    dl_predictions_df = pd.read_csv('../data/dl_predictions.csv')\n",
        "\n",
        "    # Charger les mappings pour les IDs\n",
        "    user_to_id = np.load('../data/user_to_id.npy', allow_pickle=True).item()\n",
        "    id_to_user = np.load('../data/id_to_user.npy', allow_pickle=True).item()\n",
        "    movie_to_id = np.load('../data/movie_to_id.npy', allow_pickle=True).item()\n",
        "    id_to_movie = np.load('../data/id_to_movie.npy', allow_pickle=True).item()\n",
        "\n",
        "    # Charger le fichier movies.csv pour obtenir les titres de films\n",
        "    # Assure-toi que ce fichier est dans ton dossier 'data/'\n",
        "    movies_path = '../data/movies.csv'\n",
        "    df_movies = pd.read_csv(movies_path)\n",
        "\n",
        "    print(\"Données, prédictions et mappings chargés avec succès.\")\n",
        "    print(f\"Test DataFrame shape: {test_df.shape}\")\n",
        "    print(f\"DL Predictions DataFrame shape: {dl_predictions_df.shape}\")\n",
        "    print(f\"Movies DataFrame shape: {df_movies.shape}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Erreur : Un fichier nécessaire n'a pas été trouvé. {e}\")\n",
        "    print(\"Assure-toi d'avoir exécuté les notebooks précédents et que 'movies.csv' est dans le dossier 'data/'.\")\n",
        "    print(\"Tu peux télécharger le jeu de données MovieLens ici : https://grouplens.org/datasets/movielens/\")\n",
        "    exit()\n",
        "\n",
        "# 3. Récupération des métriques des modèles de base\n",
        "# Idéalement, les métriques des modèles de base devraient être sauvegardées dans le notebook 2.\n",
        "# Pour cet exemple, nous allons les récupérer en re-évaluant le modèle SVD ou en utilisant des valeurs connues.\n",
        "# Pour le Filtrage Collaboratif, nous allons utiliser des valeurs représentatives ou re-exécuter une partie du code.\n",
        "# Le plus simple est de les récupérer directement si tu les as notées après l'exécution du notebook 2.\n",
        "\n",
        "# --- Récupération des métriques SVD ---\n",
        "# Option 1: Recharger le modèle SVD et le tester (plus robuste)\n",
        "try:\n",
        "    _, algo_svd = dump.load('../data/svd_model.pkl')\n",
        "    from surprise import Dataset, Reader\n",
        "    from surprise.model_selection import train_test_split as surprise_train_test_split\n",
        "    from surprise import accuracy\n",
        "\n",
        "    reader = Reader(rating_scale=(1, 5))\n",
        "    # Créer un testset Surprise à partir de test_df\n",
        "    svd_testset = list(test_df.apply(lambda x: (x['userId'], x['movieId'], x['rating']), axis=1))\n",
        "    predictions_svd = algo_svd.test(svd_testset)\n",
        "    rmse_svd = accuracy.rmse(predictions_svd, verbose=False)\n",
        "    mae_svd = accuracy.mae(predictions_svd, verbose=False)\n",
        "    print(f\"\\nRMSE (SVD) re-calculé : {rmse_svd:.4f}\")\n",
        "    print(f\"MAE (SVD) re-calculé : {mae_svd:.4f}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Modèle SVD non trouvé. Utilisation de valeurs par défaut pour la comparaison.\")\n",
        "    # Valeurs par défaut si le modèle SVD n'a pas été sauvegardé ou trouvé\n",
        "    rmse_svd = 0.95 # Exemple de valeur\n",
        "    mae_svd = 0.75  # Exemple de valeur\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du rechargement ou de l'évaluation du modèle SVD: {e}. Utilisation de valeurs par défaut.\")\n",
        "    rmse_svd = 0.95 # Exemple de valeur\n",
        "    mae_svd = 0.75  # Exemple de valeur\n",
        "\n",
        "# --- Récupération des métriques Filtrage Collaboratif ---\n",
        "# Le filtrage collaboratif basé sur la similarité est souvent moins performant et plus lent.\n",
        "# Nous allons utiliser des valeurs représentatives ici.\n",
        "# Si tu as les valeurs exactes de ton exécution du notebook 2, remplace-les ici.\n",
        "rmse_cf = 1.05 # Exemple de valeur\n",
        "mae_cf = 0.82  # Exemple de valeur\n",
        "print(f\"RMSE (Filtrage Collaboratif) (valeur par défaut/estimée) : {rmse_cf:.4f}\")\n",
        "print(f\"MAE (Filtrage Collaboratif) (valeur par défaut/estimée) : {mae_cf:.4f}\")\n",
        "\n",
        "\n",
        "# --- Calcul des métriques pour le modèle Deep Learning ---\n",
        "print(\"\\n--- Calcul des métriques pour le modèle Deep Learning ---\")\n",
        "y_true_dl = dl_predictions_df['true_rating'].values\n",
        "y_pred_dl = dl_predictions_df['predicted_rating_dl'].values\n",
        "\n",
        "rmse_dl = sqrt(mean_squared_error(y_true_dl, y_pred_dl))\n",
        "mae_dl = mean_absolute_error(y_true_dl, y_pred_dl)\n",
        "\n",
        "print(f\"RMSE (Deep Learning Model) : {rmse_dl:.4f}\")\n",
        "print(f\"MAE (Deep Learning Model) : {mae_dl:.4f}\")\n",
        "\n",
        "# 4. Comparaison Consolidée des Modèles\n",
        "print(\"\\n--- Tableau Comparatif des Performances des Modèles ---\")\n",
        "results_comparison = pd.DataFrame({\n",
        "    'Modèle': ['Filtrage Collaboratif', 'SVD', 'Deep Learning'],\n",
        "    'RMSE': [rmse_cf, rmse_svd, rmse_dl],\n",
        "    'MAE': [mae_cf, mae_svd, mae_dl]\n",
        "})\n",
        "\n",
        "# Trier par RMSE pour une meilleure lisibilité\n",
        "results_comparison = results_comparison.sort_values(by='RMSE', ascending=True).reset_index(drop=True)\n",
        "print(results_comparison)\n",
        "\n",
        "# 5. Visualisation de la Comparaison\n",
        "print(\"\\n--- Visualisation des Performances ---\")\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(x='Modèle', y='RMSE', data=results_comparison, palette='viridis')\n",
        "plt.title('Comparaison des RMSE des modèles')\n",
        "plt.xlabel('Modèle')\n",
        "plt.ylabel('RMSE')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(x='Modèle', y='MAE', data=results_comparison, palette='magma')\n",
        "plt.title('Comparaison des MAE des modèles')\n",
        "plt.xlabel('Modèle')\n",
        "plt.ylabel('MAE')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 6. Génération d'Exemples de Recommandations (avec le modèle Deep Learning)\n",
        "print(\"\\n--- Génération d'Exemples de Recommandations ---\")\n",
        "\n",
        "# Charger le meilleur modèle Deep Learning\n",
        "try:\n",
        "    best_dl_model = tf.keras.models.load_model('../data/deeprec_model.h5')\n",
        "    print(\"Modèle Deep Learning chargé avec succès pour les recommandations.\")\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du chargement du modèle Deep Learning : {e}\")\n",
        "    print(\"Impossible de générer des recommandations sans le modèle. Veuillez vérifier le chemin.\")\n",
        "    exit()\n",
        "\n",
        "def get_movie_title(movie_id_original):\n",
        "    \"\"\"Retourne le titre du film à partir de son ID original.\"\"\"\n",
        "    return df_movies[df_movies['movieId'] == movie_id_original]['title'].values[0]\n",
        "\n",
        "def recommend_movies_for_user(user_id_original, num_recommendations=10):\n",
        "    \"\"\"\n",
        "    Génère des recommandations de films pour un utilisateur donné.\n",
        "    Args:\n",
        "        user_id_original (int): L'ID original de l'utilisateur.\n",
        "        num_recommendations (int): Le nombre de films à recommander.\n",
        "    Returns:\n",
        "        pd.DataFrame: Un DataFrame des films recommandés avec leurs notes prédites.\n",
        "    \"\"\"\n",
        "    if user_id_original not in user_to_id:\n",
        "        print(f\"L'utilisateur {user_id_original} n'est pas dans les données d'entraînement.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    user_id_mapped = user_to_id[user_id_original]\n",
        "\n",
        "    # Obtenir tous les films que l'utilisateur a déjà notés\n",
        "    movies_rated_by_user = train_df[train_df['user_id_mapped'] == user_id_mapped]['movie_id_mapped'].tolist()\n",
        "\n",
        "    # Obtenir tous les films uniques disponibles\n",
        "    all_mapped_movies = list(movie_to_id.values())\n",
        "\n",
        "    # Filtrer les films que l'utilisateur n'a pas encore vus\n",
        "    movies_to_predict = [movie for movie in all_mapped_movies if movie not in movies_rated_by_user]\n",
        "\n",
        "    if not movies_to_predict:\n",
        "        print(f\"L'utilisateur {user_id_original} a déjà noté tous les films disponibles.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Préparer les entrées pour le modèle\n",
        "    user_inputs = np.array([user_id_mapped] * len(movies_to_predict))\n",
        "    movie_inputs = np.array(movies_to_predict)\n",
        "\n",
        "    # Faire des prédictions\n",
        "    predicted_ratings = best_dl_model.predict([user_inputs, movie_inputs]).flatten()\n",
        "    predicted_ratings = np.clip(predicted_ratings, 1.0, 5.0) # Clamper les notes\n",
        "\n",
        "    # Créer un DataFrame pour les prédictions\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'movie_id_mapped': movies_to_predict,\n",
        "        'predicted_rating': predicted_ratings\n",
        "    })\n",
        "\n",
        "    # Trier par note prédite et prendre les top N\n",
        "    predictions_df = predictions_df.sort_values(by='predicted_rating', ascending=False)\n",
        "    top_recommendations = predictions_df.head(num_recommendations)\n",
        "\n",
        "    # Mapper les IDs de films mappés vers les IDs originaux et ensuite vers les titres\n",
        "    top_recommendations['movieId'] = top_recommendations['movie_id_mapped'].map(id_to_movie)\n",
        "    top_recommendations['title'] = top_recommendations['movieId'].apply(get_movie_title)\n",
        "\n",
        "    return top_recommendations[['title', 'predicted_rating', 'movieId']]\n",
        "\n",
        "# Exemple d'utilisation : Recommander des films pour un utilisateur spécifique\n",
        "# Choisis un user_id_original qui existe dans ton dataset (par exemple, 1, 2, 3, etc.)\n",
        "example_user_id = 1 # Tu peux changer cet ID\n",
        "print(f\"\\nRecommandations pour l'utilisateur (ID original) : {example_user_id}\")\n",
        "recommendations = recommend_movies_for_user(example_user_id, num_recommendations=10)\n",
        "\n",
        "if not recommendations.empty:\n",
        "    print(recommendations)\n",
        "else:\n",
        "    print(\"Aucune recommandation générée pour cet utilisateur.\")\n",
        "\n",
        "print(\"\\n--- Analyse et comparaison des modèles terminées ! ---\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "30rxDygASZ8S"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}